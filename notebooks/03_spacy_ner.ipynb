{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraktion von Informationen aus Texten mit spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unser Datensatz und unsere Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Datensatz wurde von E. Leitner, G. Rehm und J. Moreno-Schneider  in\n",
    "\n",
    ">\n",
    "> **[Fine-grained Named Entity Recognition in Legal Documents.](https://link.springer.com/chapter/10.1007/978-3-030-33220-4_20)**\n",
    "\n",
    "vorgestellt und ist verfügbar unter\n",
    "[github](https://github.com/elenanereiss/Legal-Entity-Recognition). Der Datensatz besteht aus **Urteilen** mehrerer deutscher Gerichte mit Annotationen aller Erwähnungen von Gesetzen, Urteilen, Literatur etc.:\n",
    "\n",
    "<img src=\"img/legal_ner.png\" width=\"600px\" align=\"center\"/>\n",
    "\n",
    "Der gesamte Datensatz umfasst 66.723  Sätze. Wir wählen daraus\n",
    "\n",
    "- Urteile des Bundesarbeitsgerichts (BAG) zum **Training** und\n",
    "- Urteile des Bundesgerichtshofes (BGH) zur **Validatierung**.\n",
    "\n",
    "Die folgenden Histogramme zeigen die Verteilungen\n",
    "\n",
    "- der Satzlängen und \n",
    "- der Anzahl der Annotationen pro Klasse, wobei 'O' die \"leere\" Klasse ist:\n",
    "\n",
    "![](img/data.svg)\n",
    "\n",
    "Unsere Aufgabe wird es sein, jedes Token in einem Satz mit der richtigen Annotation zu versehen. Diese Aufgabe bezeichnet man als **named entity recognition** (**NER**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die NLP-Bibliothek spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Python-Biliothek [spaCy](https://spacy.io) bietet ***\"industrial-strength natural language processing\"*** und erlaubt uns, die obige Aufgabe zu lösen, ohne irgendetwas von NLP zu verstehen!\n",
    "Zuerst müssen wir ein [**Sprachmodell**](https://spacy.io/models) laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download de_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die obige Aufgabe werden wir mit wenigen Kommandos auf der Kommandozeile lösen. Vorher werfen wir aber einen kleinen Blick auf \"klassisches\" NLP mit spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "\n",
    "doc = nlp('Es war des Mondes heller Schein, der fiel durch Fensterscheiben rein.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wendet man das Sprachmodell auf einen Text an, so wird dieser in eine Folge von Token zerlegt und für diese Token werden\n",
    "\n",
    "- die Wortart (Part-of-Speech),\n",
    "- die Grundform und\n",
    "- der Wortvektor\n",
    "\n",
    "bestimmt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({'text': [token.text for token in doc],\n",
    "              'pos': [token.pos_ for token in doc],\n",
    "             'lemma': [token.lemma_ for token in doc],\n",
    "             'vector': [token.vector for token in doc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis ist nur zum Teil korrekt... SpaCy bietet aber noch viel mehr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: Daten aufbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben bereits von [github](https://github.com/elenanereiss/Legal-Entity-Recognition) die Daten für den BGH und das BAG heruntergeladen und im Verzeichnis `data/legal/01_raw` abgelegt. Die Dateien enthalten Beispielsätze mit Annotationen im conll-Format: pro Zeile ein Wort und die zugehörige Annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!head -n 20 data/legal/01_raw/bgh.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy kann dieses Standardformat in das eigene Format wie folgt umwandeln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!python -m spacy convert --converter ner data/legal/01_raw/bag.conll data/legal/02_train\n",
    "!python -m spacy convert --converter ner data/legal/01_raw/bgh.conll data/legal/03_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Konfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um mit spaCy per Kommandozeile ein Modell zu trainieren, muss man seit Version 3 eine Konfiguration anlegen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy init config data/legal/config_empty.cfg --lang de --pipeline 'ner' --optimize 'efficiency' --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der angelegten Konfigurationsdatei müssen wir am Anfang unter `paths.train` und `paths.dev` die Pfade zu den Trainings- und Validierungsdaten eintragen. Dies ist in der Datei `data/legal/config.cfg` bereits geschehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Daten prüfen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir lassen spaCy nun die Daten einmal kurz prüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy debug data data/legal/config.cfg --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 4: Modell trainieren und auswerten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir ein NER-Modell wie folgt trainieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!python -m spacy train data/legal/config.cfg -o data/legal/04_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auswerten können wir das trainierte Modell auf unseren Test-Daten wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!python -m spacy evaluate data/legal/04_models/model-best data/legal/03_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Tabelle zeigt pro Annotationstyp die Scores Precision (P), Recall (R) und den F1-Score (F). Die Werte variieren stark und sind noch nicht so gut. Wir haben aber auch\n",
    "\n",
    "- nur sehr kurz trainiert und\n",
    "- eine sehr unausgewogene Datenbasis: einige Annotationen treten extrem selten auf, sodass sie auch kaum gelernt werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 5: Modell verwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das trainierte Modell anzuwenden, verwenden wir die [Python-API](https://spacy.io/api) von [spaCy](https://spacy.io):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "MODEL_PATH = 'data/legal/04_models/model-best'\n",
    "nlp = spacy.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell kann nun wie folgt auf Texte angewendet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample = \"\"\"Trotz der zweifelhaften Bewertung von MDMA als \"harte Droge\"\n",
    "( vgl. BGH , Beschluss vom 3. Februar 1999 - 5 StR 705/98 ,\n",
    "juris Rn. 2 ; zum Meinungsstand Patzak in Körner / Patzak / Volkmer\n",
    ", BtMG , 8. Aufl. , Vorbem. zu §§ 29 ff. Rn. 213 mwN ; Weber , BtMG ,\n",
    "5. Aufl. , § 1 Rn. 364 mwN ) hat der Strafausspruch Bestand ,\n",
    "da die verhängte Rechtsfolge jedenfalls angemessen ist \n",
    "(§ 354 Abs. 1a Satz 1 StPO) .\"\"\"\n",
    "\n",
    "doc = nlp(sample)\n",
    "print(pd.DataFrame.from_records([{'Annotation': ent.label_, 'Text': ent.text} for ent in doc.ents]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "name": "spacy.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
